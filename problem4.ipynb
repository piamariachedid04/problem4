{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqLBllAQOcZZ",
        "outputId": "5878709c-dc03-4d10-8eab-772e631e9303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.4127 - loss: 0.7477 - val_accuracy: 0.6504 - val_loss: 0.6572\n",
            "Epoch 2/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5825 - loss: 0.6882 - val_accuracy: 0.7154 - val_loss: 0.6379\n",
            "Epoch 3/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.6412 - val_accuracy: 0.7154 - val_loss: 0.6200\n",
            "Epoch 4/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7591 - loss: 0.6059 - val_accuracy: 0.7154 - val_loss: 0.6033\n",
            "Epoch 5/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7564 - loss: 0.5751 - val_accuracy: 0.7317 - val_loss: 0.5863\n",
            "Epoch 6/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7643 - loss: 0.5554 - val_accuracy: 0.7236 - val_loss: 0.5755\n",
            "Epoch 7/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.5089 - val_accuracy: 0.7398 - val_loss: 0.5622\n",
            "Epoch 8/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8112 - loss: 0.4923 - val_accuracy: 0.7398 - val_loss: 0.5512\n",
            "Epoch 9/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7941 - loss: 0.4896 - val_accuracy: 0.7317 - val_loss: 0.5456\n",
            "Epoch 10/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4662 - val_accuracy: 0.7398 - val_loss: 0.5379\n",
            "Epoch 11/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4583 - val_accuracy: 0.7398 - val_loss: 0.5331\n",
            "Epoch 12/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4889 - val_accuracy: 0.7398 - val_loss: 0.5251\n",
            "Epoch 13/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7955 - loss: 0.4799 - val_accuracy: 0.7480 - val_loss: 0.5210\n",
            "Epoch 14/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.4749 - val_accuracy: 0.7480 - val_loss: 0.5211\n",
            "Epoch 15/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8116 - loss: 0.4551 - val_accuracy: 0.7480 - val_loss: 0.5147\n",
            "Epoch 16/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.4529 - val_accuracy: 0.7480 - val_loss: 0.5092\n",
            "Epoch 17/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7676 - loss: 0.4841 - val_accuracy: 0.7480 - val_loss: 0.5059\n",
            "Epoch 18/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8045 - loss: 0.4661 - val_accuracy: 0.7398 - val_loss: 0.5035\n",
            "Epoch 19/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4600 - val_accuracy: 0.7480 - val_loss: 0.5005\n",
            "Epoch 20/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8049 - loss: 0.4630 - val_accuracy: 0.7480 - val_loss: 0.4995\n",
            "Epoch 21/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8166 - loss: 0.4257 - val_accuracy: 0.7398 - val_loss: 0.4973\n",
            "Epoch 22/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4411 - val_accuracy: 0.7561 - val_loss: 0.4957\n",
            "Epoch 23/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7970 - loss: 0.4512 - val_accuracy: 0.7480 - val_loss: 0.4913\n",
            "Epoch 24/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.3746 - val_accuracy: 0.7480 - val_loss: 0.4906\n",
            "Epoch 25/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7922 - loss: 0.4379 - val_accuracy: 0.7480 - val_loss: 0.4879\n",
            "Epoch 26/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.4354 - val_accuracy: 0.7480 - val_loss: 0.4887\n",
            "Epoch 27/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7944 - loss: 0.4533 - val_accuracy: 0.7480 - val_loss: 0.4869\n",
            "Epoch 28/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.4378 - val_accuracy: 0.7317 - val_loss: 0.4872\n",
            "Epoch 29/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4268 - val_accuracy: 0.7154 - val_loss: 0.4872\n",
            "Epoch 30/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8174 - loss: 0.4067 - val_accuracy: 0.7317 - val_loss: 0.4857\n",
            "Epoch 31/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8163 - loss: 0.4103 - val_accuracy: 0.7398 - val_loss: 0.4846\n",
            "Epoch 32/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.4202 - val_accuracy: 0.7480 - val_loss: 0.4836\n",
            "Epoch 33/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.4196 - val_accuracy: 0.7398 - val_loss: 0.4843\n",
            "Epoch 34/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4153 - val_accuracy: 0.7561 - val_loss: 0.4820\n",
            "Epoch 35/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4212 - val_accuracy: 0.7561 - val_loss: 0.4826\n",
            "Epoch 36/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.4144 - val_accuracy: 0.7561 - val_loss: 0.4827\n",
            "Epoch 37/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8497 - loss: 0.3671 - val_accuracy: 0.7561 - val_loss: 0.4842\n",
            "Epoch 38/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8311 - loss: 0.3879 - val_accuracy: 0.7561 - val_loss: 0.4814\n",
            "Epoch 39/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.4362 - val_accuracy: 0.7561 - val_loss: 0.4817\n",
            "Epoch 40/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8354 - loss: 0.3876 - val_accuracy: 0.7561 - val_loss: 0.4844\n",
            "Epoch 41/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.4031 - val_accuracy: 0.7480 - val_loss: 0.4834\n",
            "Epoch 42/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8217 - loss: 0.4072 - val_accuracy: 0.7724 - val_loss: 0.4818\n",
            "Epoch 43/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.4202 - val_accuracy: 0.7561 - val_loss: 0.4835\n",
            "Epoch 44/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8313 - loss: 0.3800 - val_accuracy: 0.7724 - val_loss: 0.4827\n",
            "Epoch 45/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8243 - loss: 0.3895 - val_accuracy: 0.7642 - val_loss: 0.4840\n",
            "Epoch 46/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8182 - loss: 0.4186 - val_accuracy: 0.7724 - val_loss: 0.4827\n",
            "Epoch 47/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8271 - loss: 0.3867 - val_accuracy: 0.7724 - val_loss: 0.4824\n",
            "Epoch 48/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8348 - loss: 0.3952 - val_accuracy: 0.7642 - val_loss: 0.4833\n",
            "Epoch 49/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7966 - loss: 0.4289 - val_accuracy: 0.7642 - val_loss: 0.4825\n",
            "Epoch 50/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.4008 - val_accuracy: 0.7642 - val_loss: 0.4831\n",
            "Epoch 51/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.4220 - val_accuracy: 0.7724 - val_loss: 0.4814\n",
            "Epoch 52/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7841 - loss: 0.4278 - val_accuracy: 0.7805 - val_loss: 0.4809\n",
            "Epoch 53/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4004 - val_accuracy: 0.7805 - val_loss: 0.4818\n",
            "Epoch 54/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.4157 - val_accuracy: 0.7642 - val_loss: 0.4827\n",
            "Epoch 55/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.3864 - val_accuracy: 0.7724 - val_loss: 0.4843\n",
            "Epoch 56/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.3817 - val_accuracy: 0.7724 - val_loss: 0.4853\n",
            "Epoch 57/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.3931 - val_accuracy: 0.7724 - val_loss: 0.4851\n",
            "Epoch 58/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3823 - val_accuracy: 0.7642 - val_loss: 0.4848\n",
            "Epoch 59/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.4003 - val_accuracy: 0.7724 - val_loss: 0.4846\n",
            "Epoch 60/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8335 - loss: 0.4032 - val_accuracy: 0.7724 - val_loss: 0.4859\n",
            "Epoch 61/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.4151 - val_accuracy: 0.7724 - val_loss: 0.4850\n",
            "Epoch 62/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.3871 - val_accuracy: 0.7724 - val_loss: 0.4859\n",
            "Epoch 63/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.3814 - val_accuracy: 0.7724 - val_loss: 0.4851\n",
            "Epoch 64/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8380 - loss: 0.3958 - val_accuracy: 0.7724 - val_loss: 0.4878\n",
            "Epoch 65/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8264 - loss: 0.3862 - val_accuracy: 0.7642 - val_loss: 0.4881\n",
            "Epoch 66/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3761 - val_accuracy: 0.7724 - val_loss: 0.4851\n",
            "Epoch 67/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.3619 - val_accuracy: 0.7724 - val_loss: 0.4862\n",
            "Epoch 68/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.3806 - val_accuracy: 0.7724 - val_loss: 0.4863\n",
            "Epoch 69/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.3726 - val_accuracy: 0.7724 - val_loss: 0.4854\n",
            "Epoch 70/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.4018 - val_accuracy: 0.7724 - val_loss: 0.4874\n",
            "Epoch 71/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3749 - val_accuracy: 0.7642 - val_loss: 0.4852\n",
            "Epoch 72/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.3586 - val_accuracy: 0.7724 - val_loss: 0.4857\n",
            "Epoch 73/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8264 - loss: 0.3826 - val_accuracy: 0.7724 - val_loss: 0.4812\n",
            "Epoch 74/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4014 - val_accuracy: 0.7724 - val_loss: 0.4838\n",
            "Epoch 75/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8556 - loss: 0.3371 - val_accuracy: 0.7724 - val_loss: 0.4869\n",
            "Epoch 76/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.3481 - val_accuracy: 0.7805 - val_loss: 0.4864\n",
            "Epoch 77/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.3987 - val_accuracy: 0.7805 - val_loss: 0.4876\n",
            "Epoch 78/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.4015 - val_accuracy: 0.7805 - val_loss: 0.4890\n",
            "Epoch 79/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8587 - loss: 0.3654 - val_accuracy: 0.7805 - val_loss: 0.4905\n",
            "Epoch 80/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.3908 - val_accuracy: 0.7805 - val_loss: 0.4909\n",
            "Epoch 81/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.3965 - val_accuracy: 0.7805 - val_loss: 0.4889\n",
            "Epoch 82/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8323 - loss: 0.3842 - val_accuracy: 0.7805 - val_loss: 0.4916\n",
            "Epoch 83/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8351 - loss: 0.3939 - val_accuracy: 0.7805 - val_loss: 0.4936\n",
            "Epoch 84/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.3613 - val_accuracy: 0.7805 - val_loss: 0.4942\n",
            "Epoch 85/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.3293 - val_accuracy: 0.7724 - val_loss: 0.4920\n",
            "Epoch 86/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8339 - loss: 0.3672 - val_accuracy: 0.7805 - val_loss: 0.4930\n",
            "Epoch 87/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8189 - loss: 0.3899 - val_accuracy: 0.7805 - val_loss: 0.4935\n",
            "Epoch 88/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8290 - loss: 0.3681 - val_accuracy: 0.7805 - val_loss: 0.4943\n",
            "Epoch 89/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3623 - val_accuracy: 0.7805 - val_loss: 0.4950\n",
            "Epoch 90/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8300 - loss: 0.3695 - val_accuracy: 0.7724 - val_loss: 0.4960\n",
            "Epoch 91/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8642 - loss: 0.3503 - val_accuracy: 0.7805 - val_loss: 0.4950\n",
            "Epoch 92/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.4071 - val_accuracy: 0.7642 - val_loss: 0.4951\n",
            "Epoch 93/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.3483 - val_accuracy: 0.7724 - val_loss: 0.4948\n",
            "Epoch 94/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8475 - loss: 0.3424 - val_accuracy: 0.7642 - val_loss: 0.4960\n",
            "Epoch 95/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8150 - loss: 0.3849 - val_accuracy: 0.7805 - val_loss: 0.4946\n",
            "Epoch 96/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.3592 - val_accuracy: 0.7805 - val_loss: 0.4952\n",
            "Epoch 97/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8349 - loss: 0.3496 - val_accuracy: 0.7805 - val_loss: 0.4929\n",
            "Epoch 98/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.3586 - val_accuracy: 0.7886 - val_loss: 0.4970\n",
            "Epoch 99/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.3591 - val_accuracy: 0.7724 - val_loss: 0.4965\n",
            "Epoch 100/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.3659 - val_accuracy: 0.7724 - val_loss: 0.4988\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7385 - loss: 0.5692 \n",
            "Test Accuracy: 0.7468\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "     Actual  Predicted\n",
            "668       0          0\n",
            "324       0          0\n",
            "624       0          0\n",
            "690       0          0\n",
            "473       0          0\n",
            "204       0          0\n",
            "97        0          0\n",
            "336       0          1\n",
            "568       0          1\n",
            "148       0          0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "\n",
        "print(data.head())\n",
        "\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2)\n",
        "\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "predictions = (predictions > 0.5).astype(int)\n",
        "\n",
        "\n",
        "results = pd.DataFrame({'Actual': y_test, 'Predicted': predictions.flatten()})\n",
        "print(results.head(10))\n"
      ]
    }
  ]
}